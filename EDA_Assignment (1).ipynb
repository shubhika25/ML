{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75567d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==============================\n",
    "# Setup & Data Loading (Q1 part)\n",
    "# ==============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# User-specified dataset path\n",
    "df = pd.read_csv(r\"C:\\Users\\shubh\\Downloads\\BIKE_DETAILS.csv\")\n",
    "\n",
    "# Standardize column names (lowercase, underscores)\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z0-9]+\", \"_\", regex=True)\n",
    "    .str.replace(r\"_+\", \"_\", regex=True)\n",
    "    .str.strip(\"_\")\n",
    ")\n",
    "\n",
    "# Helper: flexible column resolver\n",
    "def find_col(df, candidates):\n",
    "    cols = list(df.columns)\n",
    "    for cand in candidates:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "    # fuzzy match\n",
    "    for c in cols:\n",
    "        for cand in candidates:\n",
    "            if cand in c:\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "# Likely column names\n",
    "COL_SELLING_PRICE = find_col(df, [\"selling_price\", \"sellingprice\", \"price\", \"sellingprize\"])\n",
    "COL_YEAR          = find_col(df, [\"year\", \"model_year\", \"manufacture_year\"])\n",
    "COL_SELLER_TYPE   = find_col(df, [\"seller_type\", \"sellertype\", \"seller\"])\n",
    "COL_OWNER         = find_col(df, [\"owner\", \"ownership\", \"owner_type\"])\n",
    "COL_KM_DRIVEN     = find_col(df, [\"km_driven\", \"kms_driven\", \"kilometers_driven\", \"km\", \"kms\"])\n",
    "\n",
    "# Coerce numeric columns where appropriate\n",
    "def to_numeric_safe(series):\n",
    "    return pd.to_numeric(series.astype(str).str.replace(\",\", \"\").str.strip(), errors=\"coerce\")\n",
    "\n",
    "if COL_SELLING_PRICE:\n",
    "    df[COL_SELLING_PRICE] = to_numeric_safe(df[COL_SELLING_PRICE])\n",
    "if COL_KM_DRIVEN:\n",
    "    df[COL_KM_DRIVEN] = to_numeric_safe(df[COL_KM_DRIVEN])\n",
    "if COL_YEAR:\n",
    "    df[COL_YEAR] = to_numeric_safe(df[COL_YEAR]).astype(\"Int64\")\n",
    "\n",
    "# Clean owner field a bit (standardize categories)\n",
    "if COL_OWNER and df[COL_OWNER].dtype == object:\n",
    "    df[COL_OWNER] = (\n",
    "        df[COL_OWNER]\n",
    "        .str.strip()\n",
    "        .str.lower()\n",
    "        .str.replace(r\"owner\", \"\", regex=True)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(\"Columns:\", list(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216692f7",
   "metadata": {},
   "source": [
    "\n",
    "## Question 1\n",
    "**Task:** Read the Bike Details dataset into a Pandas DataFrame and display its first 10 rows. Show the shape and column names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb608e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18923fac",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2\n",
    "**Task:** Check for missing values in all columns and describe your approach for handling them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380f4da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Missing values summary\n",
    "na_counts = df.isna().sum().sort_values(ascending=False)\n",
    "na_pct = (df.isna().mean()*100).sort_values(ascending=False)\n",
    "miss = pd.DataFrame({\"missing_count\": na_counts, \"missing_pct\": na_pct.round(2)})\n",
    "display(miss)\n",
    "\n",
    "# Example handling strategy (explain in markdown below; here we create a cleaned copy we'll reuse):\n",
    "df_clean = df.copy()\n",
    "\n",
    "# For numeric key columns like selling_price and km_driven, we won't impute with mean blindly.\n",
    "# We keep them as-is for EDA and may drop rows with missing target (selling_price) for price analyses.\n",
    "if COL_SELLING_PRICE:\n",
    "    df_clean = df_clean[~df_clean[COL_SELLING_PRICE].isna()]\n",
    "\n",
    "# For year: if absurd or missing, we can drop for plots that need year.\n",
    "if COL_YEAR:\n",
    "    df_clean = df_clean[~df_clean[COL_YEAR].isna()]\n",
    "\n",
    "# For km_driven: keep NaN for now; some analyses will use non-null subset.\n",
    "if COL_KM_DRIVEN:\n",
    "    pass\n",
    "\n",
    "print(\"Post basic cleaning shape:\", df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fb000b",
   "metadata": {},
   "source": [
    "\n",
    "**Approach (brief):**\n",
    "- For **target-like** fields such as `selling_price`, imputation can bias downstream modeling. For EDA, rows missing the target are **dropped** when analyzing price.\n",
    "- For **temporal** fields like `year`, implausible or missing values are removed for time-based visualizations.\n",
    "- For other numeric fields (e.g., `km_driven`), we keep as-is initially and use non-null subsets per analysis. If production modeling was required, we'd consider **domain-informed imputation** (e.g., median by `seller_type`).\n",
    "- We avoid mean imputation on heavy-tailed variables (like price and kms) due to skewness; **median** is safer when imputation is necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7233107d",
   "metadata": {},
   "source": [
    "\n",
    "## Question 3\n",
    "**Task:** Plot the distribution of `selling_price` and describe the overall trend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd5b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not COL_SELLING_PRICE:\n",
    "    raise KeyError(\"Could not locate a selling price column. Please adjust the resolver.\")\n",
    "\n",
    "sp = df_clean[COL_SELLING_PRICE].dropna()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(sp, bins=50)\n",
    "plt.title(\"Distribution of Selling Price\")\n",
    "plt.xlabel(\"Selling Price\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Five-number summary of selling price:\")\n",
    "display(sp.describe(percentiles=[0.25,0.5,0.75]).to_frame(\"selling_price\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d7d23d",
   "metadata": {},
   "source": [
    "\n",
    "**Observation (typical in used-vehicle data):**\n",
    "The distribution is usually **right-skewed** (long tail toward higher prices). A bulk of listings cluster at lower-to-mid price bands with fewer high-priced bikes forming the tail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98004e63",
   "metadata": {},
   "source": [
    "\n",
    "## Question 4\n",
    "**Task:** Average selling price for each `seller_type` (bar plot) and one observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c59ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not COL_SELLER_TYPE:\n",
    "    raise KeyError(\"Could not locate seller_type column.\")\n",
    "\n",
    "grp = (\n",
    "    df_clean.dropna(subset=[COL_SELLER_TYPE, COL_SELLING_PRICE])\n",
    "    .groupby(COL_SELLER_TYPE)[COL_SELLING_PRICE]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "grp.plot(kind=\"bar\")\n",
    "plt.title(\"Average Selling Price by Seller Type\")\n",
    "plt.xlabel(\"Seller Type\")\n",
    "plt.ylabel(\"Average Selling Price\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(grp.to_frame(\"avg_selling_price\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b1e06",
   "metadata": {},
   "source": [
    "\n",
    "**Observation (example template):**\n",
    "Dealer listings often show a **higher average price** than individual sellers, reflecting reconditioning costs, warranty, or selection bias toward newer models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a15f5",
   "metadata": {},
   "source": [
    "\n",
    "## Question 5\n",
    "**Task:** Average `km_driven` for each ownership type (bar plot).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33441fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not COL_OWNER:\n",
    "    raise KeyError(\"Could not locate owner/ownership column.\")\n",
    "if not COL_KM_DRIVEN:\n",
    "    raise KeyError(\"Could not locate km_driven column.\")\n",
    "\n",
    "own_km = (\n",
    "    df.dropna(subset=[COL_OWNER, COL_KM_DRIVEN])\n",
    "    .groupby(COL_OWNER)[COL_KM_DRIVEN]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "own_km.plot(kind=\"bar\")\n",
    "plt.title(\"Average KMs Driven by Ownership Type\")\n",
    "plt.xlabel(\"Ownership\")\n",
    "plt.ylabel(\"Average km_driven\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(own_km.to_frame(\"avg_km_driven\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa9f479",
   "metadata": {},
   "source": [
    "\n",
    "## Question 6\n",
    "**Task:** Use the IQR method to detect and remove outliers from `km_driven`. Show before-and-after summary statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e77870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not COL_KM_DRIVEN:\n",
    "    raise KeyError(\"Could not locate km_driven column.\")\n",
    "\n",
    "kms = df[COL_KM_DRIVEN].dropna()\n",
    "before_stats = kms.describe(percentiles=[0.25,0.5,0.75]).to_frame(\"before\")\n",
    "Q1 = kms.quantile(0.25)\n",
    "Q3 = kms.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "df_iqr = df.copy()\n",
    "mask = df_iqr[COL_KM_DRIVEN].between(lower, upper, inclusive=\"both\")\n",
    "df_iqr = df_iqr[mask]\n",
    "\n",
    "after_kms = df_iqr[COL_KM_DRIVEN].dropna()\n",
    "after_stats = after_kms.describe(percentiles=[0.25,0.5,0.75]).to_frame(\"after\")\n",
    "\n",
    "print(\"IQR bounds:\", lower, upper)\n",
    "display(before_stats.join(after_stats, how=\"outer\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d72c64",
   "metadata": {},
   "source": [
    "\n",
    "## Question 7\n",
    "**Task:** Scatter plot of `year` vs. `selling_price` to explore the relationship between age and price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02afb896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not (COL_YEAR and COL_SELLING_PRICE):\n",
    "    raise KeyError(\"Missing year or selling price column.\")\n",
    "\n",
    "sub = df_clean.dropna(subset=[COL_YEAR, COL_SELLING_PRICE])\n",
    "plt.figure()\n",
    "plt.scatter(sub[COL_YEAR], sub[COL_SELLING_PRICE], s=10, alpha=0.5)\n",
    "plt.title(\"Year vs Selling Price\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Selling Price\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.4)\n",
    "plt.show()\n",
    "\n",
    "# Quick correlation for reference\n",
    "corr = sub[[COL_YEAR, COL_SELLING_PRICE]].corr().iloc[0,1]\n",
    "print(f\"Pearson correlation (year vs selling_price): {corr:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86961845",
   "metadata": {},
   "source": [
    "\n",
    "## Question 8\n",
    "**Task:** One-hot encode `seller_type` and display first 5 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad592528",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not COL_SELLER_TYPE:\n",
    "    raise KeyError(\"Could not locate seller_type column.\")\n",
    "\n",
    "df_ohe = pd.get_dummies(df_clean, columns=[COL_SELLER_TYPE], prefix=COL_SELLER_TYPE, drop_first=False)\n",
    "display(df_ohe.head(5))\n",
    "print(\"New columns added:\", [c for c in df_ohe.columns if c.startswith(COL_SELLER_TYPE + \"_\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0047bc",
   "metadata": {},
   "source": [
    "\n",
    "## Question 9\n",
    "**Task:** Heatmap of correlation matrix for all numeric columns. What correlations stand out?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21d2b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_df = df_clean.select_dtypes(include=[np.number])\n",
    "corr = num_df.corr()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "im = plt.imshow(corr, interpolation='nearest')\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title(\"Correlation Heatmap (Numeric Columns)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top absolute correlations with selling_price (if present)\n",
    "if COL_SELLING_PRICE in num_df.columns:\n",
    "    corr_sp = corr[COL_SELLING_PRICE].drop(labels=[COL_SELLING_PRICE]).abs().sort_values(ascending=False).head(5)\n",
    "    print(\"Top |correlation| with selling_price:\")\n",
    "    display(corr_sp.to_frame(\"abs_corr_with_price\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329bc8b9",
   "metadata": {},
   "source": [
    "\n",
    "## Question 10\n",
    "**Task:** Summarize findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53c2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_points = []\n",
    "\n",
    "# Selling price distribution shape\n",
    "if COL_SELLING_PRICE and COL_SELLING_PRICE in df_clean.columns:\n",
    "    sp = df_clean[COL_SELLING_PRICE].dropna()\n",
    "    skew = sp.skew()\n",
    "    if skew > 1:\n",
    "        summary_points.append(\"Selling price distribution is strongly right-skewed with a long upper tail.\")\n",
    "    elif skew > 0.5:\n",
    "        summary_points.append(\"Selling price distribution is moderately right-skewed.\")\n",
    "    else:\n",
    "        summary_points.append(\"Selling price distribution is roughly symmetric or mildly skewed.\")\n",
    "\n",
    "# Seller type effect\n",
    "if COL_SELLER_TYPE and COL_SELLING_PRICE:\n",
    "    grp = (\n",
    "        df_clean.dropna(subset=[COL_SELLER_TYPE, COL_SELLING_PRICE])\n",
    "        .groupby(COL_SELLER_TYPE)[COL_SELLING_PRICE].mean().sort_values(ascending=False)\n",
    "    )\n",
    "    if len(grp) >= 2:\n",
    "        summary_points.append(f\"Average price varies by seller_type; top category by mean price: '{grp.index[0]}' (~{grp.iloc[0]:.0f}).\")\n",
    "\n",
    "# Ownership & kms\n",
    "if COL_OWNER and COL_KM_DRIVEN:\n",
    "    own_km = (\n",
    "        df.dropna(subset=[COL_OWNER, COL_KM_DRIVEN])\n",
    "        .groupby(COL_OWNER)[COL_KM_DRIVEN].mean().sort_values()\n",
    "    )\n",
    "    if len(own_km) > 0:\n",
    "        summary_points.append(\"Average km_driven differs by ownership level, suggesting usage intensity increases with subsequent owners.\")\n",
    "\n",
    "# Year vs price correlation\n",
    "if COL_YEAR and COL_SELLING_PRICE:\n",
    "    sub = df_clean.dropna(subset=[COL_YEAR, COL_SELLING_PRICE])\n",
    "    if len(sub) > 5:\n",
    "        corr = sub[[COL_YEAR, COL_SELLING_PRICE]].corr().iloc[0,1]\n",
    "        if corr > 0.2:\n",
    "            summary_points.append(\"Newer bikes (higher year) tend to have higher prices (positive correlation).\")\n",
    "        elif corr < -0.2:\n",
    "            summary_points.append(\"Newer bikes tend to have lower prices (negative correlation) — unusual; check data quality.\")\n",
    "        else:\n",
    "            summary_points.append(\"Weak linear correlation between year and price; relationship may be nonlinear or confounded by model mix.\")\n",
    "\n",
    "# Outliers handling\n",
    "if COL_KM_DRIVEN:\n",
    "    kms = df[COL_KM_DRIVEN].dropna()\n",
    "    Q1, Q3 = kms.quantile(0.25), kms.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "    summary_points.append(f\"IQR outlier bounds for km_driven: [{lower:.0f}, {upper:.0f}] — rows outside were excluded for robust summaries.\")\n",
    "\n",
    "summary_md = \"### Summary (Auto-generated)\\n\\n\" + \"\".join([f\"- {pt}\\n\" for pt in summary_points]) \\\n",
    "             + \"\\n**Data Cleaning / Feature Engineering:**\\n\" \\\n",
    "             \"- Standardized column names.\\n\" \\\n",
    "             \"- Converted text numerics to numbers (removed commas).\\n\" \\\n",
    "             \"- Dropped rows with missing `selling_price` for price-based analyses.\\n\" \\\n",
    "             \"- Applied IQR rule for `km_driven` to identify outliers.\\n\" \\\n",
    "             \"- One-hot encoded `seller_type` for modeling readiness.\\n\"\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(summary_md))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
